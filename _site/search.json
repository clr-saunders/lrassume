[
  {
    "objectID": "reference/check_linearity.html",
    "href": "reference/check_linearity.html",
    "title": "check_linearity",
    "section": "",
    "text": "check_linearity\ncheck_linearity.py Module for analyzing linear relationships between numeric features and a target variable.\nThis module provides tools for identifying features in a pandas DataFrame that have a strong linear relationship with a specified numeric target column using Pearson correlation.\n\n\n\ncheck_linearity(df, target, threshold=0.7) Identifies numeric features with absolute Pearson correlation above a given threshold relative to the target column.\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ncheck_linearity\nIdentify features with a specified strength of linear relationship to the target.\n\n\n\n\n\ncheck_linearity.check_linearity(df, target, threshold=0.7)\nIdentify features with a specified strength of linear relationship to the target.\nThis function identifies all of the numeric features in a DataFrame and computes the Pearson correlation coefficient between each numeric feature in the DataFrame and the specified numeric target column. It returns a DataFrame containing the features whose absolute correlation with the target is greater than or equal to the given threshold along with their correlation values.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndf\npandas.DataFrame\nInput DataFrame with feature columns and the target column. Only numeric features will be considered.\nrequired\n\n\ntarget\nstr\nName of the target column. The column must be numeric and the name must match the column name in the data.\nrequired\n\n\nthreshold\nfloat\nMinimum absolute Pearson correlation required for a feature to be considered strongly correlated with the target. Must be between 0 and 1. Default is 0.7.\n0.7\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npandas.DataFrame\nA DataFrame with the following columns: - feature : str Name of the feature column. - correlation : float Pearson correlation coefficient between the feature and the target. The DataFrame is sorted by absolute correlation in descending order.\n\n\n\n\n\n\n&gt;&gt;&gt; df_example = pd.DataFrame({\n...     \"sqft\": [500, 700, 900, 1100],\n...     \"num_rooms\": [1, 2, 1, 3],\n...     \"age\": [40, 25, 20, 5],\n...     \"distance_to_city\": [10, 12, 11, 13],\n...     \"price\": [150, 210, 260, 320]\n... })\n&gt;&gt;&gt; check_linearity(df=df_example, target=\"price\", threshold=0.7)\n    feature  correlation\n0       sqft        0.994\n1         age       -0.952\n2   num_rooms        0.703"
  },
  {
    "objectID": "reference/check_linearity.html#functions",
    "href": "reference/check_linearity.html#functions",
    "title": "check_linearity",
    "section": "",
    "text": "check_linearity(df, target, threshold=0.7) Identifies numeric features with absolute Pearson correlation above a given threshold relative to the target column."
  },
  {
    "objectID": "reference/check_linearity.html#functions-1",
    "href": "reference/check_linearity.html#functions-1",
    "title": "check_linearity",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncheck_linearity\nIdentify features with a specified strength of linear relationship to the target.\n\n\n\n\n\ncheck_linearity.check_linearity(df, target, threshold=0.7)\nIdentify features with a specified strength of linear relationship to the target.\nThis function identifies all of the numeric features in a DataFrame and computes the Pearson correlation coefficient between each numeric feature in the DataFrame and the specified numeric target column. It returns a DataFrame containing the features whose absolute correlation with the target is greater than or equal to the given threshold along with their correlation values.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndf\npandas.DataFrame\nInput DataFrame with feature columns and the target column. Only numeric features will be considered.\nrequired\n\n\ntarget\nstr\nName of the target column. The column must be numeric and the name must match the column name in the data.\nrequired\n\n\nthreshold\nfloat\nMinimum absolute Pearson correlation required for a feature to be considered strongly correlated with the target. Must be between 0 and 1. Default is 0.7.\n0.7\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npandas.DataFrame\nA DataFrame with the following columns: - feature : str Name of the feature column. - correlation : float Pearson correlation coefficient between the feature and the target. The DataFrame is sorted by absolute correlation in descending order.\n\n\n\n\n\n\n&gt;&gt;&gt; df_example = pd.DataFrame({\n...     \"sqft\": [500, 700, 900, 1100],\n...     \"num_rooms\": [1, 2, 1, 3],\n...     \"age\": [40, 25, 20, 5],\n...     \"distance_to_city\": [10, 12, 11, 13],\n...     \"price\": [150, 210, 260, 320]\n... })\n&gt;&gt;&gt; check_linearity(df=df_example, target=\"price\", threshold=0.7)\n    feature  correlation\n0       sqft        0.994\n1         age       -0.952\n2   num_rooms        0.703"
  },
  {
    "objectID": "reference/index.html",
    "href": "reference/index.html",
    "title": "Function reference",
    "section": "",
    "text": "All functions in the package\n\n\n\ncheck_independence\ncheck_independence.py\n\n\ncheck_linearity\ncheck_linearity.py\n\n\ncheck_multicollinearity_vif\nCompute multicollinearity diagnostics using Variance Inflation Factor (VIF).\n\n\ncheck_homoscedasticity\nHomoscedasticity diagnostics for linear regression.",
    "crumbs": [
      "API Reference"
    ]
  },
  {
    "objectID": "reference/index.html#functions",
    "href": "reference/index.html#functions",
    "title": "Function reference",
    "section": "",
    "text": "All functions in the package\n\n\n\ncheck_independence\ncheck_independence.py\n\n\ncheck_linearity\ncheck_linearity.py\n\n\ncheck_multicollinearity_vif\nCompute multicollinearity diagnostics using Variance Inflation Factor (VIF).\n\n\ncheck_homoscedasticity\nHomoscedasticity diagnostics for linear regression.",
    "crumbs": [
      "API Reference"
    ]
  },
  {
    "objectID": "reference/check_independence.html",
    "href": "reference/check_independence.html",
    "title": "check_independence",
    "section": "",
    "text": "check_independence\ncheck_independence.py Module for testing independence of residuals in linear regression models.\nThis module provides tools for detecting autocorrelation in residuals from a fitted linear regression model using the Durbin-Watson statistic. Independence of residuals is a key assumption for valid inference in linear modeling.\n\n\n\ncheck_independence(df, target) Fits a linear regression model and tests for independence of residuals using the Durbin-Watson statistic to detect autocorrelation.\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ncheck_independence\nChecks the independence of residuals using the Durbin-Watson statistic.\n\n\n\n\n\ncheck_independence.check_independence(df, target)\nChecks the independence of residuals using the Durbin-Watson statistic.\nThis function fits a linear regression model on the provided dataframe, calculates the residuals, and then computes the Durbin-Watson score to determine if autocorrelation is present in the residuals. Independence is a key assumption for valid inference in linear modeling.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndf\npandas.DataFrame\nInput DataFrame with feature columns and the target column. Only numeric features will be used as predictors.\nrequired\n\n\ntarget\nstr\nName of the target column. The column must be numeric and the name must match the column name in the dataframe.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ndict\nA dictionary containing: - ‘dw_statistic’ (float): The calculated Durbin-Watson value (0 to 4). - ‘is_independent’ (bool): True if the statistic is near 2 (typically 1.5 to 2.5), suggesting no significant autocorrelation. - ‘message’ (str): A brief interpretation of the result.\n\n\n\n\n\n\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; df = pd.DataFrame({\n...     \"x1\": [1, 2, 3, 4, 5],\n...     \"x2\": [2, 4, 5, 7, 8],\n...     \"y\": [10, 20, 25, 35, 40]\n... })\n&gt;&gt;&gt; check_independence(df, target=\"y\")\n{'dw_statistic': np.float64(0.0727), 'is_independent': False, 'message': 'Positive autocorrelation detected. Residuals may not be independent.'}"
  },
  {
    "objectID": "reference/check_independence.html#functions",
    "href": "reference/check_independence.html#functions",
    "title": "check_independence",
    "section": "",
    "text": "check_independence(df, target) Fits a linear regression model and tests for independence of residuals using the Durbin-Watson statistic to detect autocorrelation."
  },
  {
    "objectID": "reference/check_independence.html#functions-1",
    "href": "reference/check_independence.html#functions-1",
    "title": "check_independence",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncheck_independence\nChecks the independence of residuals using the Durbin-Watson statistic.\n\n\n\n\n\ncheck_independence.check_independence(df, target)\nChecks the independence of residuals using the Durbin-Watson statistic.\nThis function fits a linear regression model on the provided dataframe, calculates the residuals, and then computes the Durbin-Watson score to determine if autocorrelation is present in the residuals. Independence is a key assumption for valid inference in linear modeling.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndf\npandas.DataFrame\nInput DataFrame with feature columns and the target column. Only numeric features will be used as predictors.\nrequired\n\n\ntarget\nstr\nName of the target column. The column must be numeric and the name must match the column name in the dataframe.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ndict\nA dictionary containing: - ‘dw_statistic’ (float): The calculated Durbin-Watson value (0 to 4). - ‘is_independent’ (bool): True if the statistic is near 2 (typically 1.5 to 2.5), suggesting no significant autocorrelation. - ‘message’ (str): A brief interpretation of the result.\n\n\n\n\n\n\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; df = pd.DataFrame({\n...     \"x1\": [1, 2, 3, 4, 5],\n...     \"x2\": [2, 4, 5, 7, 8],\n...     \"y\": [10, 20, 25, 35, 40]\n... })\n&gt;&gt;&gt; check_independence(df, target=\"y\")\n{'dw_statistic': np.float64(0.0727), 'is_independent': False, 'message': 'Positive autocorrelation detected. Residuals may not be independent.'}"
  },
  {
    "objectID": "CONTRIBUTING.html",
    "href": "CONTRIBUTING.html",
    "title": "Contributing",
    "section": "",
    "text": "Contributions of all kinds are welcome here, and they are greatly appreciated! Every little bit helps, and credit will always be given.\n\n\nYou can contribute in many ways, for example:\n\nReport bugs\nFix Bugs\nImplement Features\nWrite Documentation\nSubmit Feedback\n\n\n\nReport bugs at https://github.com//lrassume/issues.\nIf you are reporting a bug, please follow the template guidelines. The more detailed your report, the easier and thus faster we can help you.\n\n\n\nLook through the GitHub issues for bugs. Anything labelled with bug and help wanted is open to whoever wants to implement it. When you decide to work on such an issue, please assign yourself to it and add a comment that you’ll be working on that, too. If you see another issue without the help wanted label, just post a comment, the maintainers are usually happy for any support that they can get.\n\n\n\nLook through the GitHub issues for features. Anything labelled with enhancement and help wanted is open to whoever wants to implement it. As for fixing bugs, please assign yourself to the issue and add a comment that you’ll be working on that, too. If another enhancement catches your fancy, but it doesn’t have the help wanted label, just post a comment, the maintainers are usually happy for any support that they can get.\n\n\n\nlrassume could always use more documentation, whether as part of the official documentation, in docstrings, or even on the web in blog posts, articles, and such. Just open an issue to let us know what you will be working on so that we can provide you with guidance.\n\n\n\nThe best way to send feedback is to file an issue at https://github.com//lrassume/issues. If your feedback fits the format of one of the issue templates, please use that. Remember that this is a volunteer-driven project and everybody has limited time.\n\n\n\n\nReady to contribute? Here’s how to set up lrassume for local development.\n\nFork the https://github.com//lrassume repository on GitHub.\nClone your fork locally (if you want to work locally)\ngit clone git@github.com:your_name_here/lrassume.git\nInstall hatch.\nCreate a branch for local development using the default branch (typically main) as a starting point. Use fix or feat as a prefix for your branch name. Hatch will manage dependencies and environments for you!\ngit checkout main\ngit checkout -b fix-name-of-your-bugfix\nNow you can make your changes locally.\nWhen you’re done making changes, apply the quality assurance tools and check that your changes pass our test suite. This is all included with tox\nhatch run test:run\nCommit your changes and push your branch to GitHub. Please use semantic commit messages.\ngit add .\ngit commit -m \"fix: summarize your changes\"\ngit push -u origin fix-name-of-your-bugfix\nOpen the link displayed in the message when pushing your new branch in order to submit a pull request.\n\n\n\nBefore you submit a pull request, check that it meets these guidelines:\n\nThe pull request should include tests.\nIf the pull request adds functionality, the docs should be updated. Put your new functionality into a function with a docstring.\nYour pull request will automatically be checked by the full test suite. It needs to pass all of them before it can be considered for merging."
  },
  {
    "objectID": "CONTRIBUTING.html#example-contributions",
    "href": "CONTRIBUTING.html#example-contributions",
    "title": "Contributing",
    "section": "",
    "text": "You can contribute in many ways, for example:\n\nReport bugs\nFix Bugs\nImplement Features\nWrite Documentation\nSubmit Feedback\n\n\n\nReport bugs at https://github.com//lrassume/issues.\nIf you are reporting a bug, please follow the template guidelines. The more detailed your report, the easier and thus faster we can help you.\n\n\n\nLook through the GitHub issues for bugs. Anything labelled with bug and help wanted is open to whoever wants to implement it. When you decide to work on such an issue, please assign yourself to it and add a comment that you’ll be working on that, too. If you see another issue without the help wanted label, just post a comment, the maintainers are usually happy for any support that they can get.\n\n\n\nLook through the GitHub issues for features. Anything labelled with enhancement and help wanted is open to whoever wants to implement it. As for fixing bugs, please assign yourself to the issue and add a comment that you’ll be working on that, too. If another enhancement catches your fancy, but it doesn’t have the help wanted label, just post a comment, the maintainers are usually happy for any support that they can get.\n\n\n\nlrassume could always use more documentation, whether as part of the official documentation, in docstrings, or even on the web in blog posts, articles, and such. Just open an issue to let us know what you will be working on so that we can provide you with guidance.\n\n\n\nThe best way to send feedback is to file an issue at https://github.com//lrassume/issues. If your feedback fits the format of one of the issue templates, please use that. Remember that this is a volunteer-driven project and everybody has limited time."
  },
  {
    "objectID": "CONTRIBUTING.html#get-started",
    "href": "CONTRIBUTING.html#get-started",
    "title": "Contributing",
    "section": "",
    "text": "Ready to contribute? Here’s how to set up lrassume for local development.\n\nFork the https://github.com//lrassume repository on GitHub.\nClone your fork locally (if you want to work locally)\ngit clone git@github.com:your_name_here/lrassume.git\nInstall hatch.\nCreate a branch for local development using the default branch (typically main) as a starting point. Use fix or feat as a prefix for your branch name. Hatch will manage dependencies and environments for you!\ngit checkout main\ngit checkout -b fix-name-of-your-bugfix\nNow you can make your changes locally.\nWhen you’re done making changes, apply the quality assurance tools and check that your changes pass our test suite. This is all included with tox\nhatch run test:run\nCommit your changes and push your branch to GitHub. Please use semantic commit messages.\ngit add .\ngit commit -m \"fix: summarize your changes\"\ngit push -u origin fix-name-of-your-bugfix\nOpen the link displayed in the message when pushing your new branch in order to submit a pull request.\n\n\n\nBefore you submit a pull request, check that it meets these guidelines:\n\nThe pull request should include tests.\nIf the pull request adds functionality, the docs should be updated. Put your new functionality into a function with a docstring.\nYour pull request will automatically be checked by the full test suite. It needs to pass all of them before it can be considered for merging."
  },
  {
    "objectID": "docs/index.html",
    "href": "docs/index.html",
    "title": "Welcome to lrassume’s Documentation ’",
    "section": "",
    "text": ":maxdepth: 2 :hidden: :caption: Contents:\nHome \n\nThis is the landing page of your docs. you can update it as you’d like to. This documentation example uses myst markdown as the primary documentation syntax.\n:::{button-link} https://www.pyopensci.org/python-package-guide/documentation/hosting-tools/myst-markdown-rst-doc-syntax.html :color: primary :class: sd-rounded-pill float-left\nLearn more about myst in our pyOpenSci packaging guide.\n:::\nMyst is a version of markdown that has more formatting flexibility. This is what a sphinx directive looks like using myst markdown formatting:\n:::{toctree}\n:maxdepth: 2\n:caption: Contents:\n:::\nIf you see syntax like the syntax below, you are looking at rst.\n.. toctree::\n   :maxdepth: 2\n   :caption: Contents:\n\n\n\n\nCopyright © 2026 CHOT.\nFree software distributed under the MIT License."
  },
  {
    "objectID": "docs/index.html#overview",
    "href": "docs/index.html#overview",
    "title": "Welcome to lrassume’s Documentation ’",
    "section": "",
    "text": ":maxdepth: 2 :hidden: :caption: Contents:\nHome \n\nThis is the landing page of your docs. you can update it as you’d like to. This documentation example uses myst markdown as the primary documentation syntax.\n:::{button-link} https://www.pyopensci.org/python-package-guide/documentation/hosting-tools/myst-markdown-rst-doc-syntax.html :color: primary :class: sd-rounded-pill float-left\nLearn more about myst in our pyOpenSci packaging guide.\n:::\nMyst is a version of markdown that has more formatting flexibility. This is what a sphinx directive looks like using myst markdown formatting:\n:::{toctree}\n:maxdepth: 2\n:caption: Contents:\n:::\nIf you see syntax like the syntax below, you are looking at rst.\n.. toctree::\n   :maxdepth: 2\n   :caption: Contents:"
  },
  {
    "objectID": "docs/index.html#copyright",
    "href": "docs/index.html#copyright",
    "title": "Welcome to lrassume’s Documentation ’",
    "section": "",
    "text": "Copyright © 2026 CHOT.\nFree software distributed under the MIT License."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html",
    "href": "CODE_OF_CONDUCT.html",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.\nWe pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.\n\n\n\nExamples of behavior that contributes to a positive environment for our community include:\n\nDemonstrating empathy and kindness toward other people\nBeing respectful of differing opinions, viewpoints, and experiences\nGiving and gracefully accepting constructive feedback\nAccepting responsibility and apologizing to those affected by our mistakes, and learning from the experience\nFocusing on what is best not just for us as individuals, but for the overall community\n\nExamples of unacceptable behavior include:\n\nThe use of sexualized language or imagery, and sexual attention or advances of any kind\nTrolling, insulting or derogatory comments, and personal or political attacks\nPublic or private harassment\nPublishing others’ private information, such as a physical or email address, without their explicit permission\nOther conduct which could reasonably be considered inappropriate in a professional setting\n\n\n\n\nCommunity leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.\nCommunity leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.\n\n\n\nThis Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.\n\n\n\nThe community leaders for this project are the authors, Harpreet Singh, Ojasv Issar, Tanav Singh Bajaj and Claire Saunders.\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at clamwoodsaunders@gmail.com. All complaints will be reviewed and investigated promptly and fairly.\nAll community leaders are obligated to respect the privacy and security of the reporter of any incident.\n\n\n\nCommunity leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:\n\n\nCommunity Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.\nConsequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.\n\n\n\nCommunity Impact: A violation through a single incident or series of actions.\nConsequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.\n\n\n\nCommunity Impact: A serious violation of community standards, including sustained inappropriate behavior.\nConsequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.\n\n\n\nCommunity Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.\nConsequence: A permanent ban from any sort of public interaction within the community.\n\n\n\n\nThis Code of Conduct is adapted from the Contributor Covenant, version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.\nCommunity Impact Guidelines were inspired by Mozilla’s code of conduct enforcement ladder.\nFor answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#our-pledge",
    "href": "CODE_OF_CONDUCT.html#our-pledge",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.\nWe pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#our-standards",
    "href": "CODE_OF_CONDUCT.html#our-standards",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "Examples of behavior that contributes to a positive environment for our community include:\n\nDemonstrating empathy and kindness toward other people\nBeing respectful of differing opinions, viewpoints, and experiences\nGiving and gracefully accepting constructive feedback\nAccepting responsibility and apologizing to those affected by our mistakes, and learning from the experience\nFocusing on what is best not just for us as individuals, but for the overall community\n\nExamples of unacceptable behavior include:\n\nThe use of sexualized language or imagery, and sexual attention or advances of any kind\nTrolling, insulting or derogatory comments, and personal or political attacks\nPublic or private harassment\nPublishing others’ private information, such as a physical or email address, without their explicit permission\nOther conduct which could reasonably be considered inappropriate in a professional setting"
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#enforcement-responsibilities",
    "href": "CODE_OF_CONDUCT.html#enforcement-responsibilities",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.\nCommunity leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#scope",
    "href": "CODE_OF_CONDUCT.html#scope",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#enforcement",
    "href": "CODE_OF_CONDUCT.html#enforcement",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "The community leaders for this project are the authors, Harpreet Singh, Ojasv Issar, Tanav Singh Bajaj and Claire Saunders.\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at clamwoodsaunders@gmail.com. All complaints will be reviewed and investigated promptly and fairly.\nAll community leaders are obligated to respect the privacy and security of the reporter of any incident."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#enforcement-guidelines",
    "href": "CODE_OF_CONDUCT.html#enforcement-guidelines",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:\n\n\nCommunity Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.\nConsequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.\n\n\n\nCommunity Impact: A violation through a single incident or series of actions.\nConsequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.\n\n\n\nCommunity Impact: A serious violation of community standards, including sustained inappropriate behavior.\nConsequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.\n\n\n\nCommunity Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.\nConsequence: A permanent ban from any sort of public interaction within the community."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#attribution",
    "href": "CODE_OF_CONDUCT.html#attribution",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "This Code of Conduct is adapted from the Contributor Covenant, version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.\nCommunity Impact Guidelines were inspired by Mozilla’s code of conduct enforcement ladder.\nFor answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations."
  },
  {
    "objectID": "CHANGELOG.html",
    "href": "CHANGELOG.html",
    "title": "Changelog",
    "section": "",
    "text": "All notable changes to this project will be documented in this file.\nThe format is based on Keep a Changelog, and this project adheres to Semantic Versioning. testing ## [Unreleased]\n\nUpcoming features and fixes\n\n\n\n\nFirst release"
  },
  {
    "objectID": "CHANGELOG.html#section",
    "href": "CHANGELOG.html#section",
    "title": "Changelog",
    "section": "",
    "text": "First release"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to lrassume",
    "section": "",
    "text": "Package\n \n\n\nMeta\n \n\n\n\nlrassume (Linear Regression Assumption Validator) is a Python package for validating the core assumptions of linear regression models. It provides statistical tests and diagnostic tools to assess independence, linearity, multicollinearity, and homoscedasticity in your regression workflows.\n\n\n\nIndependence Testing: Durbin-Watson test to detect autocorrelation in residuals\nLinearity Assessment: Pearson correlation analysis to identify linear relationships with the target\nMulticollinearity Detection: Variance Inflation Factor (VIF) calculation with configurable thresholds\nHomoscedasticity Testing: Multiple statistical tests (Breusch-Pagan, White, Goldfeld-Quandt) to detect heteroscedasticity\n\n\n\n\n\n\n\nThis option is recommended if you want to use lrassume in your own projects and do not need to modify the source code.\npip install -i https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple/ lrassume\n\n\n\n\nThis option is recommended if you want to develop, modify, or contribute to lrassume.\nThis project uses Conda to manage the Python environment and pip to install project dependencies.\n\n\n\ngit clone https://github.com/UBC-MDS/lrassume.git\ncd lrassume\n\n\n\n\nFrom the project root directory:\nconda env create -f environment.yml\nconda activate lrassume\n\nThe environment.yml file installs Python only. All runtime dependencies are specified in pyproject.toml.\n\n\n\n\n\npip install -e .\n\n\n\n\n\nIf you prefer not to use Conda, you can install the package directly using pip:\ngit clone https://github.com/UBC-MDS/lrassume.git\ncd lrassume\npip install -e .\n\n\n\n\n\nThe test suite is executed using pytest. In CI this is managed via Hatch, but tests can also be run locally using pytest.\n\n\n\nconda install pytest\n# or\npip install pytest\n\n\n\n\npytest\n\n\n\n\n\nThis project uses GitHub Actions to automatically run the test suite.\nThe tests are executed automatically on: - Pull requests - Pushes to the main branch - A scheduled weekly run\nThe test suite is executed using Hatch, which runs the project’s configured pytest test environment across multiple operating systems and Python versions.\nNo manual action is required to trigger these tests.\nThe GitHub Actions workflow responsible for running the test suite is located at:\n.github/workflows/test.yml\n\n\n\nThe full package documentation is built with Quartodoc and deployed automatically to GitHub Pages.\nLive documentation: https://ubc-mds.github.io/lrassume/\n\n\nTo preview documentation changes before pushing:\n\nEnsure you are in the development environment:\n\n   conda activate lrassume\n\nInstall documentation dependencies:\n\n   pip install -e \".[docs]\"\n\nBuild the documentation:\n\n   quartodoc build\n\nPreview the documentation locally:\n\n   quarto preview\nThis will open the documentation site in your browser.\n\n\n\nTo update documentation:\n\nEdit docstrings in Python source files (lrassume/*.py)\nRebuild locally using the steps above to verify changes\nCommit and push to your branch\n\nNote: The documentation is automatically generated from your Python docstrings.\n\n\n\nDocumentation deployment is fully automated using GitHub Actions.\nOn every push to the main branch:\n\nGitHub Actions builds the documentation using Quarto and Quartodoc\nThe rendered site is deployed to GitHub Pages\n\nNo manual deployment steps are required.\nThe workflow file can be found at:\n.github/workflows/docs-publish.yml\n\n\n\n\n\n\nThis function fits a linear model and checks for autocorrelation in the residuals.\nimport pandas as pd\nfrom lrassume import check_independence\n\n# Create sample data\ndf = pd.DataFrame({\n    \"x1\": [1, 2, 3, 4, 5],\n    \"x2\": [2, 4, 5, 7, 8],\n    \"y\": [10, 20, 25, 35, 40]\n})\n\n# Check independence of residuals\nresult = check_independence(df, target=\"y\")\n\n# View results\nprint(result['dw_statistic'])    \nprint(result['is_independent'])  \nprint(result['message'])         \nInterpreting the Durbin-Watson statistic: - 1.5 to 2.5: No significant autocorrelation (residuals are independent) ✓ - &lt; 1.5: Positive autocorrelation detected - &gt; 2.5: Negative autocorrelation detected\nNote: The function automatically uses all numeric columns (except the target) as predictors and handles the intercept term internally.\n\n\n\nIdentify features with strong linear relationships to the target:\nimport pandas as pd\nfrom lrassume import check_linearity\n\ndf = pd.DataFrame({\n    \"sqft\": [500, 700, 900, 1100],\n    \"num_rooms\": [1, 2, 1, 3],\n    \"age\": [40, 25, 20, 5],\n    \"price\": [150, 210, 260, 320]\n})\n\nlinear_features = check_linearity(df, target=\"price\", threshold=0.7)\nprint(linear_features)\n#  feature  correlation\n# 0    sqft        0.999\n# 1     age       -0.990\n\n\n\nCompute Variance Inflation Factors to detect multicollinearity:\nimport pandas as pd\nfrom lrassume import check_multicollinearity_vif\n\nX = pd.DataFrame({\"sqft\": [800, 900, 1000, 1100, 1200, 1300, 1400, 1500],\n     \"bedrooms\": [1, 2, 1, 3, 2, 4, 3, 5],\n     \"age\": [30, 5, 40, 10, 25, 15, 35, 20]\n})\n\nvif_table, summary = check_multicollinearity_vif(X, warn_threshold=5.0)\nprint(summary['overall_status'])  # 'ok', 'warn', or 'severe'\n# severe\nprint(vif_table)\n#    feature        vif   level\n# 0  bedrooms  11.100000  severe\n# 1     sqft   9.402273    warn\n# 2      age   3.102273      ok\n\n\n\nTest for constant variance in residuals:\nimport pandas as pd\nimport numpy as np\nfrom lrassume import check_homoscedasticity\nnp.random.seed(123)\nX = pd.DataFrame({\n    'x1': np.linspace(1, 100, 100),\n    'x2': np.random.randn(100)\n})\ny = pd.Series(2 * X['x1'] + 3 * X['x2'] + np.random.randn(100))\n\ntest_results, summary = check_homoscedasticity(X, y, method=\"breusch_pagan\")\nprint(summary['overall_conclusion'])  # 'homoscedastic' \nprint(test_results)\n#            test  statistic  p_value     conclusion  significant\n# 0  breusch_pagan      1.111   0.5737  homoscedastic        False\n\n\n\n\n\n\nResiduals should be independent of each other (no autocorrelation). Violations occur in time-series or spatially correlated data.\n\n\n\nThe relationship between predictors and the target should be approximately linear. Non-linear relationships may require transformations or non-linear models.\n\n\n\nPredictors should not be highly correlated with each other. High multicollinearity inflates standard errors and makes coefficient estimates unstable.\n\n\n\nResiduals should have constant variance across all levels of predictors. Heteroscedasticity leads to inefficient estimates and incorrect standard errors.\n\n\n\n\n\n\nfrom sklearn.linear_model import LinearRegression\nfrom lrassume import check_homoscedasticity\n\nmodel = LinearRegression().fit(X, y)\ntest_results, summary = check_homoscedasticity(\n    X, y, \n    fitted_model=model,\n    method=\"all\"  # Run all tests\n)\n\n\n\nfrom lrassume import check_multicollinearity_vif\n\n# Automatically drop non-numeric columns\nvif_table, summary = check_multicollinearity_vif(\n    df, \n    target_column='price',\n    categorical='drop'\n)\nprint(summary['dropped_non_numeric'])  # Lists dropped columns\n\n\n\n# Stricter multicollinearity detection\nvif_table, summary = check_multicollinearity_vif(\n    X, \n    warn_threshold=3.0,\n    severe_threshold=5.0\n)\n\n# More conservative homoscedasticity testing\ntest_results, summary = check_homoscedasticity(\n    X, y, \n    alpha=0.01  # 99% confidence level\n)\n\n\n\n\n\n\n\n\n\n\n\n\nFunction\nPurpose\nKey Parameters\n\n\n\n\ncheck_independence()\nDurbin-Watson test for autocorrelation\ndf, target\n\n\ncheck_linearity()\nPearson correlation analysis\ndf, target, threshold\n\n\ncheck_multicollinearity_vif()\nVIF calculation\nX, warn_threshold, severe_threshold\n\n\ncheck_homoscedasticity()\nHeteroscedasticity testing\nX, y, method, alpha\n\n\n\n\n\n\n\n\n\nVIF &lt; 5: No concerning multicollinearity\n5 ≤ VIF &lt; 10: Moderate multicollinearity (warning)\nVIF ≥ 10: Severe multicollinearity (action recommended)\n\n\n\n\n\nDW ≈ 2: No autocorrelation (independence satisfied)\nDW &lt; 1.5: Positive autocorrelation\nDW &gt; 2.5: Negative autocorrelation\n\n\n\n\n\np-value &gt; α: Fail to reject null hypothesis (homoscedastic)\np-value ≤ α: Reject null hypothesis (heteroscedastic)\n\n\n\n\n\nContributions are welcome! Please see our Code of Conduct for community guidelines.\n\n\n\nCopyright © 2026 CHOT.\nFree software distributed under the MIT License.\n\n\n\nFor bug reports and feature requests, please open an issue on GitHub.",
    "crumbs": [
      "Welcome to lrassume"
    ]
  },
  {
    "objectID": "index.html#features",
    "href": "index.html#features",
    "title": "Welcome to lrassume",
    "section": "",
    "text": "Independence Testing: Durbin-Watson test to detect autocorrelation in residuals\nLinearity Assessment: Pearson correlation analysis to identify linear relationships with the target\nMulticollinearity Detection: Variance Inflation Factor (VIF) calculation with configurable thresholds\nHomoscedasticity Testing: Multiple statistical tests (Breusch-Pagan, White, Goldfeld-Quandt) to detect heteroscedasticity",
    "crumbs": [
      "Welcome to lrassume"
    ]
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "Welcome to lrassume",
    "section": "",
    "text": "This option is recommended if you want to use lrassume in your own projects and do not need to modify the source code.\npip install -i https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple/ lrassume\n\n\n\n\nThis option is recommended if you want to develop, modify, or contribute to lrassume.\nThis project uses Conda to manage the Python environment and pip to install project dependencies.\n\n\n\ngit clone https://github.com/UBC-MDS/lrassume.git\ncd lrassume\n\n\n\n\nFrom the project root directory:\nconda env create -f environment.yml\nconda activate lrassume\n\nThe environment.yml file installs Python only. All runtime dependencies are specified in pyproject.toml.\n\n\n\n\n\npip install -e .\n\n\n\n\n\nIf you prefer not to use Conda, you can install the package directly using pip:\ngit clone https://github.com/UBC-MDS/lrassume.git\ncd lrassume\npip install -e .",
    "crumbs": [
      "Welcome to lrassume"
    ]
  },
  {
    "objectID": "index.html#running-the-test-suite-developers",
    "href": "index.html#running-the-test-suite-developers",
    "title": "Welcome to lrassume",
    "section": "",
    "text": "The test suite requires pytest, which is a development dependency and is not installed automatically for users of the package.\n\n\n\nconda install pytest\n# or\npip install pytest\n\n\n\n\npytest",
    "crumbs": [
      "Welcome to lrassume"
    ]
  },
  {
    "objectID": "index.html#quick-start",
    "href": "index.html#quick-start",
    "title": "Welcome to lrassume",
    "section": "",
    "text": "This function fits a linear model and checks for autocorrelation in the residuals.\nimport pandas as pd\nfrom lrassume import check_independence\n\n# Create sample data\ndf = pd.DataFrame({\n    \"x1\": [1, 2, 3, 4, 5],\n    \"x2\": [2, 4, 5, 7, 8],\n    \"y\": [10, 20, 25, 35, 40]\n})\n\n# Check independence of residuals\nresult = check_independence(df, target=\"y\")\n\n# View results\nprint(result['dw_statistic'])    \nprint(result['is_independent'])  \nprint(result['message'])         \nInterpreting the Durbin-Watson statistic: - 1.5 to 2.5: No significant autocorrelation (residuals are independent) ✓ - &lt; 1.5: Positive autocorrelation detected - &gt; 2.5: Negative autocorrelation detected\nNote: The function automatically uses all numeric columns (except the target) as predictors and handles the intercept term internally.\n\n\n\nIdentify features with strong linear relationships to the target:\nimport pandas as pd\nfrom lrassume import check_linearity\n\ndf = pd.DataFrame({\n    \"sqft\": [500, 700, 900, 1100],\n    \"num_rooms\": [1, 2, 1, 3],\n    \"age\": [40, 25, 20, 5],\n    \"price\": [150, 210, 260, 320]\n})\n\nlinear_features = check_linearity(df, target=\"price\", threshold=0.7)\nprint(linear_features)\n#  feature  correlation\n# 0    sqft        0.999\n# 1     age       -0.990\n\n\n\nCompute Variance Inflation Factors to detect multicollinearity:\nimport pandas as pd\nfrom lrassume import check_multicollinearity_vif\n\nX = pd.DataFrame({\"sqft\": [800, 900, 1000, 1100, 1200, 1300, 1400, 1500],\n     \"bedrooms\": [1, 2, 1, 3, 2, 4, 3, 5],\n     \"age\": [30, 5, 40, 10, 25, 15, 35, 20]\n})\n\nvif_table, summary = check_multicollinearity_vif(X, warn_threshold=5.0)\nprint(summary['overall_status'])  # 'ok', 'warn', or 'severe'\n# severe\nprint(vif_table)\n#    feature        vif   level\n# 0  bedrooms  11.100000  severe\n# 1     sqft   9.402273    warn\n# 2      age   3.102273      ok\n\n\n\nTest for constant variance in residuals:\nimport pandas as pd\nimport numpy as np\nfrom lrassume import check_homoscedasticity\nnp.random.seed(123)\nX = pd.DataFrame({\n    'x1': np.linspace(1, 100, 100),\n    'x2': np.random.randn(100)\n})\ny = pd.Series(2 * X['x1'] + 3 * X['x2'] + np.random.randn(100))\n\ntest_results, summary = check_homoscedasticity(X, y, method=\"breusch_pagan\")\nprint(summary['overall_conclusion'])  # 'homoscedastic' \nprint(test_results)\n#            test  statistic  p_value     conclusion  significant\n# 0  breusch_pagan      1.111   0.5737  homoscedastic        False",
    "crumbs": [
      "Welcome to lrassume"
    ]
  },
  {
    "objectID": "index.html#core-assumptions-tested",
    "href": "index.html#core-assumptions-tested",
    "title": "Welcome to lrassume",
    "section": "",
    "text": "Residuals should be independent of each other (no autocorrelation). Violations occur in time-series or spatially correlated data.\n\n\n\nThe relationship between predictors and the target should be approximately linear. Non-linear relationships may require transformations or non-linear models.\n\n\n\nPredictors should not be highly correlated with each other. High multicollinearity inflates standard errors and makes coefficient estimates unstable.\n\n\n\nResiduals should have constant variance across all levels of predictors. Heteroscedasticity leads to inefficient estimates and incorrect standard errors.",
    "crumbs": [
      "Welcome to lrassume"
    ]
  },
  {
    "objectID": "index.html#advanced-usage",
    "href": "index.html#advanced-usage",
    "title": "Welcome to lrassume",
    "section": "",
    "text": "from sklearn.linear_model import LinearRegression\nfrom lrassume import check_homoscedasticity\n\nmodel = LinearRegression().fit(X, y)\ntest_results, summary = check_homoscedasticity(\n    X, y, \n    fitted_model=model,\n    method=\"all\"  # Run all tests\n)\n\n\n\nfrom lrassume import check_multicollinearity_vif\n\n# Automatically drop non-numeric columns\nvif_table, summary = check_multicollinearity_vif(\n    df, \n    target_column='price',\n    categorical='drop'\n)\nprint(summary['dropped_non_numeric'])  # Lists dropped columns\n\n\n\n# Stricter multicollinearity detection\nvif_table, summary = check_multicollinearity_vif(\n    X, \n    warn_threshold=3.0,\n    severe_threshold=5.0\n)\n\n# More conservative homoscedasticity testing\ntest_results, summary = check_homoscedasticity(\n    X, y, \n    alpha=0.01  # 99% confidence level\n)",
    "crumbs": [
      "Welcome to lrassume"
    ]
  },
  {
    "objectID": "index.html#function-reference",
    "href": "index.html#function-reference",
    "title": "Welcome to lrassume",
    "section": "",
    "text": "Function\nPurpose\nKey Parameters\n\n\n\n\ncheck_independence()\nDurbin-Watson test for autocorrelation\ndf, target\n\n\ncheck_linearity()\nPearson correlation analysis\ndf, target, threshold\n\n\ncheck_multicollinearity_vif()\nVIF calculation\nX, warn_threshold, severe_threshold\n\n\ncheck_homoscedasticity()\nHeteroscedasticity testing\nX, y, method, alpha",
    "crumbs": [
      "Welcome to lrassume"
    ]
  },
  {
    "objectID": "index.html#interpretation-guidelines",
    "href": "index.html#interpretation-guidelines",
    "title": "Welcome to lrassume",
    "section": "",
    "text": "VIF &lt; 5: No concerning multicollinearity\n5 ≤ VIF &lt; 10: Moderate multicollinearity (warning)\nVIF ≥ 10: Severe multicollinearity (action recommended)\n\n\n\n\n\nDW ≈ 2: No autocorrelation (independence satisfied)\nDW &lt; 1.5: Positive autocorrelation\nDW &gt; 2.5: Negative autocorrelation\n\n\n\n\n\np-value &gt; α: Fail to reject null hypothesis (homoscedastic)\np-value ≤ α: Reject null hypothesis (heteroscedastic)",
    "crumbs": [
      "Welcome to lrassume"
    ]
  },
  {
    "objectID": "index.html#contributing",
    "href": "index.html#contributing",
    "title": "Welcome to lrassume",
    "section": "",
    "text": "Contributions are welcome! Please see our Code of Conduct for community guidelines.",
    "crumbs": [
      "Welcome to lrassume"
    ]
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Welcome to lrassume",
    "section": "",
    "text": "Copyright © 2026 CHOT.\nFree software distributed under the MIT License.",
    "crumbs": [
      "Welcome to lrassume"
    ]
  },
  {
    "objectID": "index.html#support",
    "href": "index.html#support",
    "title": "Welcome to lrassume",
    "section": "",
    "text": "For bug reports and feature requests, please open an issue on GitHub.",
    "crumbs": [
      "Welcome to lrassume"
    ]
  },
  {
    "objectID": "DEVELOPMENT.html",
    "href": "DEVELOPMENT.html",
    "title": "Development Guide",
    "section": "",
    "text": "Welcome to your shiny new package. This page will help you get started with using Hatch to manage your package.\nIf you look at your project, you will see that a pyproject.toml file. This file stores both your package configuration and settings for development tools like Hatch that you will use to work on your package.\nThis file is written using a .toml format. You can learn more about toml here. Here’s the TL&DR:\n\nEach [] section in the toml file is called a table.\nYou can nest tables with double brackets like this[[]]\nTables contain information about a element that you want to configure.\n\nWe are using Hatch as the default packaging tool. Hatch allows you to configure and run environments and scripts similar to workflow tools like tox or nox.\nHach, by default, uses virtual environments (venv) to manage environments. But you can configure it to use other environment tools.Read the hatch documentation to learn more about environments.\nFor this template, we have set up Hatch environments for you to use. At the bottom of your pyproject.toml file, notice a hatch environment section that looks like this:\n########################################\n# Hatch Environments\n########################################\nBelow is the Hatch environment to install your package. Notice that it defines pip and twine as two packages that the environment needs.\n[tool.hatch.envs.build]\ndescription = \"\"\"Test the installation the package.\"\"\"\ndependencies = [\n    \"pip\",\n    \"twine\",\n]\nThe table below defines the scripts that you will run build and check your package.\n[tool.hatch.envs.build.scripts]\ncheck = [\n    \"pip check\",\n    \"hatch build {args:--clean}\",\n    \"twine check dist/*\",\n]\ndetached = true\nYou can enter that environment to check it out:\n$ hatch shell build\nIf you run pip list, in the environment, twine will be there:\n$ pip list\nHatch by default, installs your package in editable mode (-e) into its virtual environments. But if detached=True is set, then it will skip installing your package into the virtual enviornment.\n\n\nBelow you see the Hatch environment test table.\ntool.hatch.envs says, “Hey, Hatch, this is the definition for an environment.” test is the name of the environment.\nThe environment below defines the dependencies that Hatch needs to install into the environment named test.\n[tool.hatch.envs.test]\ndescription = \"\"\"Run the test suite.\"\"\"\ndependencies = [\n    \"pytest\",\n    \"pytest-cov\",\n    \"pytest-raises\",\n    \"pytest-randomly\",\n    \"pytest-xdist\",\n]\nTo enter a Hatch environment use:\nhatch shell environmentname\nSo you can enter the test environment above with:\nhatch shell test\n\n\n\nIf the environment has a matrix associated with it, that tells Hatch to run the test scripts across different Python versions.\n[[tool.hatch.envs.test.matrix]]\npython = [\"3.10\", \"3.11\", \"3.12\", \"3.13\"]\nIf you run hatch shell test, you will see the output below. To enter an environment with a matrix attached to it, you need to pick the Python environment version that you want to open.\n$ hatch shell test                           \nEnvironment `test` defines a matrix, choose one of the following instead:\n\ntest.py3.10\ntest.py3.11\ntest.py3.12\ntest.py3.13\nOpen the Python 3.13 environment like this:\n$ hatch shell test.py3.13\nTo leave an environment use:\n$ deactivate\n\n\n\nIn the tests section of your pyproject.toml, you will see a tool.hatch.envs.test.scripts table.\nThis table defines the commands that you want Hatch to run in the test environment. Notice that the script has one command called run.\n[tool.hatch.envs.test.scripts]\nrun = \"pytest {args:--cov=greatproject --cov-report=term-missing}\"\nTo run this script , use:\nhatch run test:run\n\nhatch run: calls Hatch and tells it that it will be running a command\ntest:run: defines the environment you want it to run (test) and defines the name of the “script” to berun.\n\nIf you have a Hatch matrix setup for tests, it will both install the necessary Python version using UV and run your tests on each version of the Python versions that you declare in the matrix table. In this case, there are 4 Python versions in the environment, so your tests will run 4 times, once in each Python version listed in the matrix table.\n@lwasser ➜ /workspaces/pyopensci-scipy25-create-python-package (main) $ hatch run test:run\n──────────────────────────────────────────────────────────────────────── test.py3.10 ────────────────────────────────────────────────────────────────────────\n==================================================================== test session starts ====================================================================\nplatform linux -- Python 3.10.16, pytest-8.4.1, pluggy-1.6.0\nUsing --randomly-seed=1490740387\nrootdir: /workspaces/pyopensci-scipy25-create-python-package\nconfigfile: pyproject.toml\ntestpaths: tests\nplugins: xdist-3.8.0, randomly-3.16.0, raises-0.11, cov-6.2.1\ncollected 2 items                                                                                                                                           \n\ntests/system/test_import.py .                                                                                                                         [ 50%]\ntests/unit/test_example.py .                                                                                                                          [100%]\n\n====================================================================== tests coverage =======================================================================\n_____________________________________________________ coverage: platform linux, python 3.10.16-final-0 ______________________________________________________\n\nName                           Stmts   Miss Branch BrPart    Cover   Missing\n----------------------------------------------------------------------------\nsrc/greatproject/__init__.py       0      0      0      0  100.00%\nsrc/greatproject/example.py        2      0      0      0  100.00%\n----------------------------------------------------------------------------\nTOTAL                              2      0      0      0  100.00%\n===================================================================== 2 passed in 0.05s =====================================================================\n──────────────────────────────────────────────────────────────────────── test.py3.11 ────────────────────────────────────────────────────────────────────────\n==================================================================== test session starts ====================================================================\nplatform linux -- Python 3.11.12, pytest-8.4.1, pluggy-1.6.0\nUsing --randomly-seed=1596865075\nrootdir: /workspaces/pyopensci-scipy25-create-python-package\nconfigfile: pyproject.toml\ntestpaths: tests\nplugins: xdist-3.8.0, randomly-3.16.0, raises-0.11, cov-6.2.1\ncollected 2 items                                                                                                                                           \n\ntests/system/test_import.py .                                                                                                                         [ 50%]\ntests/unit/test_example.py .                                                                                                                          [100%]\n\n====================================================================== tests coverage =======================================================================\n_____________________________________________________ coverage: platform linux, python 3.11.12-final-0 ______________________________________________________\n\nName                           Stmts   Miss Branch BrPart    Cover   Missing\n----------------------------------------------------------------------------\nsrc/greatproject/__init__.py       0      0      0      0  100.00%\nsrc/greatproject/example.py        2      0      0      0  100.00%\n----------------------------------------------------------------------------\nTOTAL                              2      0      0      0  100.00%\n===================================================================== 2 passed in 0.05s =====================================================================\n\n\n\nYou can build your package using the environment and scripts defined in the build tables:\nhatch run build:check\nThis script builds and checks the output distribution files of your package.\nThis build environment table declares that pip and twine should be added to that environment. Adding pip to the environment ensures that it is a current, up-to-date version.\n[tool.hatch.envs.build]\ndescription = \"\"\"Build and test your package.\"\"\"\ndependencies = [\n    \"pip\",\n    \"twine\",\n]\ndetached = true\n# This table installs created the command hatch run install:check which will build and check your package.\n[tool.hatch.envs.install.scripts]\ncheck = [\n    \"pip check\",\n    \"hatch build {args:--clean}\",\n    \"twine check dist/*\",\n]\nThis uses the above environment and tells hatch to run\n\npip check, # verifies your dependencies\nhatch build --clean\n\ntwine check dist/* # this checks your distribution for metadata and other potential issues. to build and test your package."
  },
  {
    "objectID": "DEVELOPMENT.html#build-your-package",
    "href": "DEVELOPMENT.html#build-your-package",
    "title": "Development Guide",
    "section": "",
    "text": "You can build your package using the environment and scripts defined in the build tables:\nhatch run build:check\nThis script builds and checks the output distribution files of your package.\nThis build environment table declares that pip and twine should be added to that environment. Adding pip to the environment ensures that it is a current, up-to-date version.\n[tool.hatch.envs.build]\ndescription = \"\"\"Build and test your package.\"\"\"\ndependencies = [\n    \"pip\",\n    \"twine\",\n]\ndetached = true\n# This table installs created the command hatch run install:check which will build and check your package.\n[tool.hatch.envs.install.scripts]\ncheck = [\n    \"pip check\",\n    \"hatch build {args:--clean}\",\n    \"twine check dist/*\",\n]\nThis uses the above environment and tells hatch to run\n\npip check, # verifies your dependencies\nhatch build --clean\n\ntwine check dist/* # this checks your distribution for metadata and other potential issues. to build and test your package."
  },
  {
    "objectID": "reference/check_multicollinearity_vif.html",
    "href": "reference/check_multicollinearity_vif.html",
    "title": "check_multicollinearity_vif",
    "section": "",
    "text": "check_multicollinearity_vif(X, *, target_column=None, warn_threshold=5.0, severe_threshold=10.0, categorical='error', drop_constant=True)\nCompute multicollinearity diagnostics using Variance Inflation Factor (VIF).\nMulticollinearity refers to strong linear dependence among predictor variables. It does NOT involve the target variable. VIF is defined for each predictor x_j as:\nVIF_j = 1 / (1 - R_j^2)\nwhere R_j^2 is the coefficient of determination from regressing x_j on all other predictors. High VIF indicates inflated variance of coefficient estimates in ordinary least squares (OLS), leading to unstable coefficients.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nX\npd.DataFrame\nDataFrame of predictors (features). Each column is treated as a predictor. If the target column is included, specify it via target_column.\nrequired\n\n\ntarget_column\nstr\nName of the target column to exclude from VIF calculation. If None, assumes X contains only predictors. Raises ValueError if specified but not found in X.\nNone\n\n\nwarn_threshold\nfloat\nVIF threshold for flagging features as “warn”. Common heuristic: VIF &gt; 5 suggests moderate multicollinearity.\n5.0\n\n\nsevere_threshold\nfloat\nVIF threshold for flagging features as “severe”. Common heuristic: VIF &gt; 10 suggests severe multicollinearity. Must be &gt;= warn_threshold.\n10.0\n\n\ncategorical\nCategoricalHandling\nHow to handle non-numeric columns: - “error”: Raise ValueError if non-numeric columns are present - “drop”: Remove non-numeric columns and report in summary\n\"error\"\n\n\ndrop_constant\nbool\nWhether to drop constant columns (where all values are identical). - If True: Constant columns are removed and reported in summary - If False: May raise ValueError during VIF computation due to singularity\nTrue\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npd.DataFrame\nOne row per feature with columns: - “feature” (str): Feature name - “vif” (float): VIF value (may be inf for perfect collinearity) - “level” (str): One of {“ok”, “warn”, “severe”} Rows are sorted by VIF in descending order.\n\n\ndict\nOverall diagnostics containing: - “overall_status” (str): Worst level found (“ok”, “warn”, or “severe”) - “n_features” (int): Number of features evaluated - “n_warn” (int): Count of features with warn-level VIF - “n_severe” (int): Count of features with severe-level VIF - “warn_threshold” (float): Echo of input threshold - “severe_threshold” (float): Echo of input threshold - “dropped_non_numeric” (list[str]): Non-numeric columns dropped (if categorical=“drop”) - “dropped_constant” (list[str]): Constant columns dropped (if drop_constant=True)\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nValueError\n- If target_column is specified but not found in X - If categorical=“error” and non-numeric columns exist - If drop_constant=False and constant columns prevent VIF computation - If warn_threshold &lt;= 0 or severe_threshold &lt; warn_threshold - If fewer than 2 features remain after dropping columns - If X contains missing values (NaN/None) in evaluated predictors\n\n\n\n\n\n\n\nVIF measures linear dependence among predictors only, not their relationship with the target variable.\nVIF = inf indicates perfect multicollinearity (one predictor is a perfect linear combination of others).\nThe auxiliary regressions used to compute R_j^2 include an intercept term.\nConstant columns have no variance and will cause numerical issues if not dropped."
  },
  {
    "objectID": "reference/check_multicollinearity_vif.html#parameters",
    "href": "reference/check_multicollinearity_vif.html#parameters",
    "title": "check_multicollinearity_vif",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nX\npd.DataFrame\nDataFrame of predictors (features). Each column is treated as a predictor. If the target column is included, specify it via target_column.\nrequired\n\n\ntarget_column\nstr\nName of the target column to exclude from VIF calculation. If None, assumes X contains only predictors. Raises ValueError if specified but not found in X.\nNone\n\n\nwarn_threshold\nfloat\nVIF threshold for flagging features as “warn”. Common heuristic: VIF &gt; 5 suggests moderate multicollinearity.\n5.0\n\n\nsevere_threshold\nfloat\nVIF threshold for flagging features as “severe”. Common heuristic: VIF &gt; 10 suggests severe multicollinearity. Must be &gt;= warn_threshold.\n10.0\n\n\ncategorical\nCategoricalHandling\nHow to handle non-numeric columns: - “error”: Raise ValueError if non-numeric columns are present - “drop”: Remove non-numeric columns and report in summary\n\"error\"\n\n\ndrop_constant\nbool\nWhether to drop constant columns (where all values are identical). - If True: Constant columns are removed and reported in summary - If False: May raise ValueError during VIF computation due to singularity\nTrue"
  },
  {
    "objectID": "reference/check_multicollinearity_vif.html#returns",
    "href": "reference/check_multicollinearity_vif.html#returns",
    "title": "check_multicollinearity_vif",
    "section": "",
    "text": "Type\nDescription\n\n\n\n\npd.DataFrame\nOne row per feature with columns: - “feature” (str): Feature name - “vif” (float): VIF value (may be inf for perfect collinearity) - “level” (str): One of {“ok”, “warn”, “severe”} Rows are sorted by VIF in descending order.\n\n\ndict\nOverall diagnostics containing: - “overall_status” (str): Worst level found (“ok”, “warn”, or “severe”) - “n_features” (int): Number of features evaluated - “n_warn” (int): Count of features with warn-level VIF - “n_severe” (int): Count of features with severe-level VIF - “warn_threshold” (float): Echo of input threshold - “severe_threshold” (float): Echo of input threshold - “dropped_non_numeric” (list[str]): Non-numeric columns dropped (if categorical=“drop”) - “dropped_constant” (list[str]): Constant columns dropped (if drop_constant=True)"
  },
  {
    "objectID": "reference/check_multicollinearity_vif.html#raises",
    "href": "reference/check_multicollinearity_vif.html#raises",
    "title": "check_multicollinearity_vif",
    "section": "",
    "text": "Type\nDescription\n\n\n\n\nValueError\n- If target_column is specified but not found in X - If categorical=“error” and non-numeric columns exist - If drop_constant=False and constant columns prevent VIF computation - If warn_threshold &lt;= 0 or severe_threshold &lt; warn_threshold - If fewer than 2 features remain after dropping columns - If X contains missing values (NaN/None) in evaluated predictors"
  },
  {
    "objectID": "reference/check_multicollinearity_vif.html#notes",
    "href": "reference/check_multicollinearity_vif.html#notes",
    "title": "check_multicollinearity_vif",
    "section": "",
    "text": "VIF measures linear dependence among predictors only, not their relationship with the target variable.\nVIF = inf indicates perfect multicollinearity (one predictor is a perfect linear combination of others).\nThe auxiliary regressions used to compute R_j^2 include an intercept term.\nConstant columns have no variance and will cause numerical issues if not dropped."
  },
  {
    "objectID": "reference/check_homoscedasticity.html",
    "href": "reference/check_homoscedasticity.html",
    "title": "check_homoscedasticity",
    "section": "",
    "text": "check_homoscedasticity\nHomoscedasticity diagnostics for linear regression.\nThis module contains utilities to detect heteroscedasticity (non-constant variance) in residuals for linear regression workflows. Heteroscedasticity violates a key assumption of ordinary least squares (OLS) regression and can lead to inefficient estimates and incorrect standard errors.\nThe module provides the check_homoscedasticity function which implements three widely-used statistical tests: Breusch-Pagan, White, and Goldfeld-Quandt.\n\n\ncheck_homoscedasticity : Test residuals for constant variance\n\n\n\nBasic usage: &gt;&gt;&gt; import pandas as pd &gt;&gt;&gt; import numpy as np &gt;&gt;&gt; from lrassume import check_homoscedasticity &gt;&gt;&gt; &gt;&gt;&gt; X = pd.DataFrame({‘x1’: range(100), ‘x2’: np.random.randn(100)}) &gt;&gt;&gt; y = pd.Series(2 * X[‘x1’] + np.random.randn(100)) &gt;&gt;&gt; results, summary = check_homoscedasticity(X, y) &gt;&gt;&gt; print(summary[‘overall_conclusion’]) ‘homoscedastic’\n\n\n\nAll tests assume that residuals come from a linear regression model. If using non-linear models, interpret results with caution.\n\n\n\n.. [1] Breusch, T. S., & Pagan, A. R. (1979). A simple test for heteroscedasticity and random coefficient variation. Econometrica, 47(5), 1287-1294.\n.. [2] White, H. (1980). A heteroskedasticity-consistent covariance matrix estimator and a direct test for heteroskedasticity. Econometrica, 48(4), 817-838.\n.. [3] Goldfeld, S. M., & Quandt, R. E. (1965). Some tests for homoscedasticity. Journal of the American Statistical Association, 60(310), 539-547.\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ncheck_homoscedasticity\nTest for homoscedasticity (constant variance) in linear regression residuals.\n\n\n\n\n\ncheck_homoscedasticity.check_homoscedasticity(X, y, *, method='breusch_pagan', alpha=0.05, fitted_model=None, residuals=None, fitted_values=None)\nTest for homoscedasticity (constant variance) in linear regression residuals.\nHomoscedasticity is the assumption that residuals have constant variance across all levels of the independent variables. Violation of this assumption (heteroscedasticity) leads to inefficient coefficient estimates and incorrect standard errors in ordinary least squares (OLS) regression.\nThis function implements multiple statistical tests to detect heteroscedasticity:\n\nBreusch-Pagan test: Tests whether residual variance depends linearly on predictors. Null hypothesis: homoscedasticity (constant variance).\nWhite test: More general test that allows for non-linear relationships between variance and predictors. Includes squared terms and interactions. Null hypothesis: homoscedasticity.\nGoldfeld-Quandt test: Splits data by a predictor and compares variance in two subsets. Useful for detecting variance that increases/decreases with a specific predictor.\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nX\npd.DataFrame\nDataFrame of predictors (features). Each column is a predictor variable. Must contain only numeric columns.\nrequired\n\n\ny\npd.Series\nTarget variable (response). Must have the same length as X.\nrequired\n\n\nmethod\nTestMethod\nStatistical test(s) to perform: - “breusch_pagan”: Breusch-Pagan Lagrange multiplier test - “white”: White’s general heteroscedasticity test - “goldfeld_quandt”: Goldfeld-Quandt test (splits on first predictor by default) - “all”: Run all available tests\n\"breusch_pagan\"\n\n\nalpha\nfloat\nSignificance level for hypothesis tests. Common values: 0.01, 0.05, 0.10. Must be between 0 and 1 (exclusive).\n0.05\n\n\nfitted_model\noptional\nPre-fitted regression model object with predict() method. If None, an OLS model will be fitted internally using X and y. Useful for avoiding refitting when model already exists.\nNone\n\n\nresiduals\nnp.ndarray\nPre-computed residuals (y - y_pred). Must have same length as y. If None, residuals will be computed from fitted_model or internal fit. Cannot be specified without fitted_values.\nNone\n\n\nfitted_values\nnp.ndarray\nPre-computed fitted values (y_pred). Must have same length as y. If None, fitted values will be computed from fitted_model or internal fit. Cannot be specified without residuals.\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npd.DataFrame\nOne row per test performed, with columns: - “test” (str): Name of the test performed - “statistic” (float): Test statistic value, rounded to 3 decimals - “p_value” (float): P-value for the test, rounded to 4 decimals - “conclusion” (str): One of {“homoscedastic”, “heteroscedastic”} - “significant” (bool): True if p_value &lt; alpha (reject null hypothesis) Rows are sorted by test name alphabetically.\n\n\ndict\nOverall diagnostics containing: - “overall_conclusion” (str): “homoscedastic” if all tests pass, otherwise “heteroscedastic” - “n_tests_performed” (int): Number of tests conducted - “n_tests_significant” (int): Number of tests rejecting homoscedasticity - “alpha” (float): Echo of significance level used - “n_observations” (int): Sample size - “n_predictors” (int): Number of predictor variables - “recommendation” (str): Suggested action if heteroscedasticity detected\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nValueError\n- If X contains non-numeric columns - If X and y have different lengths - If alpha is not between 0 and 1 - If residuals is provided without fitted_values or vice versa - If residuals/fitted_values length doesn’t match y - If fewer than 10 observations are available (insufficient for testing)\n\n\nTypeError\n- If fitted_model is provided but lacks predict() method - If X is not a pandas DataFrame - If y is not a pandas Series\n\n\n\n\n\n\n\nAll tests assume residuals from a linear regression model.\nTests use chi-square or F-distributions depending on the method.\nThe Breusch-Pagan test is most powerful against linear heteroscedasticity.\nThe White test is more general but may have lower power with small samples.\nGoldfeld-Quandt test requires ordering data, which may be arbitrary for multivariate predictors.\nIf heteroscedasticity is detected, consider using robust standard errors (e.g., HC3, HC4) or weighted least squares (WLS) regression.\nMissing values in X or y will raise an error; clean data beforehand.\n\n\n\n\nBasic usage with internal model fitting:\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; np.random.seed(42)\n&gt;&gt;&gt; X = pd.DataFrame({\n...     'x1': np.linspace(1, 100, 100),\n...     'x2': np.random.randn(100)\n... })\n&gt;&gt;&gt; y = pd.Series(2 * X['x1'] + 3 * X['x2'] + np.random.randn(100))\n&gt;&gt;&gt; test_results, summary = check_homoscedasticity(X, y)\n&gt;&gt;&gt; print(summary[\"overall_conclusion\"])\n'homoscedastic'\nUsing a pre-fitted model:\n&gt;&gt;&gt; from sklearn.linear_model import LinearRegression\n&gt;&gt;&gt; model = LinearRegression().fit(X, y)\n&gt;&gt;&gt; test_results, summary = check_homoscedasticity(\n...     X, y, fitted_model=model\n... )\n&gt;&gt;&gt; print(test_results)\n          test  statistic   p_value      conclusion  significant\n0  breusch_pagan      2.345      0.309  homoscedastic        False\nRunning all tests:\n&gt;&gt;&gt; test_results, summary = check_homoscedasticity(\n...     X, y, method=\"all\", alpha=0.01\n... )\n&gt;&gt;&gt; print(summary[\"n_tests_performed\"])\n3\n&gt;&gt;&gt; print(summary[\"n_tests_significant\"])\n0\nDetecting heteroscedasticity (variance increases with x):\n&gt;&gt;&gt; X_hetero = pd.DataFrame({\n...     'x1': np.linspace(1, 100, 100)\n... })\n&gt;&gt;&gt; errors = np.random.randn(100) * X_hetero['x1']  # variance increases\n&gt;&gt;&gt; y_hetero = pd.Series(2 * X_hetero['x1'] + errors)\n&gt;&gt;&gt; test_results, summary = check_homoscedasticity(X_hetero, y_hetero)\n&gt;&gt;&gt; print(summary[\"overall_conclusion\"])\n'heteroscedastic'\n&gt;&gt;&gt; print(summary[\"recommendation\"])\n'Consider using robust standard errors (HC3/HC4) or weighted least squares.'\nUsing pre-computed residuals and fitted values:\n&gt;&gt;&gt; model = LinearRegression().fit(X, y)\n&gt;&gt;&gt; y_pred = model.predict(X)\n&gt;&gt;&gt; resid = y - y_pred\n&gt;&gt;&gt; test_results, summary = check_homoscedasticity(\n...     X, y,\n...     residuals=resid,\n...     fitted_values=y_pred\n... )\n&gt;&gt;&gt; print(test_results)\n          test  statistic   p_value      conclusion  significant\n0  breusch_pagan      2.345      0.309  homoscedastic        False\n\n\n\n.. [1] Breusch, T. S., & Pagan, A. R. (1979). A simple test for heteroscedasticity and random coefficient variation. Econometrica, 47(5), 1287-1294.\n.. [2] White, H. (1980). A heteroskedasticity-consistent covariance matrix estimator and a direct test for heteroskedasticity. Econometrica, 48(4), 817-838.\n.. [3] Goldfeld, S. M., & Quandt, R. E. (1965). Some tests for homoscedasticity. Journal of the American Statistical Association, 60(310), 539-547."
  },
  {
    "objectID": "reference/check_homoscedasticity.html#functions",
    "href": "reference/check_homoscedasticity.html#functions",
    "title": "check_homoscedasticity",
    "section": "",
    "text": "check_homoscedasticity : Test residuals for constant variance"
  },
  {
    "objectID": "reference/check_homoscedasticity.html#examples",
    "href": "reference/check_homoscedasticity.html#examples",
    "title": "check_homoscedasticity",
    "section": "",
    "text": "Basic usage: &gt;&gt;&gt; import pandas as pd &gt;&gt;&gt; import numpy as np &gt;&gt;&gt; from lrassume import check_homoscedasticity &gt;&gt;&gt; &gt;&gt;&gt; X = pd.DataFrame({‘x1’: range(100), ‘x2’: np.random.randn(100)}) &gt;&gt;&gt; y = pd.Series(2 * X[‘x1’] + np.random.randn(100)) &gt;&gt;&gt; results, summary = check_homoscedasticity(X, y) &gt;&gt;&gt; print(summary[‘overall_conclusion’]) ‘homoscedastic’"
  },
  {
    "objectID": "reference/check_homoscedasticity.html#notes",
    "href": "reference/check_homoscedasticity.html#notes",
    "title": "check_homoscedasticity",
    "section": "",
    "text": "All tests assume that residuals come from a linear regression model. If using non-linear models, interpret results with caution."
  },
  {
    "objectID": "reference/check_homoscedasticity.html#references",
    "href": "reference/check_homoscedasticity.html#references",
    "title": "check_homoscedasticity",
    "section": "",
    "text": ".. [1] Breusch, T. S., & Pagan, A. R. (1979). A simple test for heteroscedasticity and random coefficient variation. Econometrica, 47(5), 1287-1294.\n.. [2] White, H. (1980). A heteroskedasticity-consistent covariance matrix estimator and a direct test for heteroskedasticity. Econometrica, 48(4), 817-838.\n.. [3] Goldfeld, S. M., & Quandt, R. E. (1965). Some tests for homoscedasticity. Journal of the American Statistical Association, 60(310), 539-547."
  },
  {
    "objectID": "reference/check_homoscedasticity.html#functions-1",
    "href": "reference/check_homoscedasticity.html#functions-1",
    "title": "check_homoscedasticity",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncheck_homoscedasticity\nTest for homoscedasticity (constant variance) in linear regression residuals.\n\n\n\n\n\ncheck_homoscedasticity.check_homoscedasticity(X, y, *, method='breusch_pagan', alpha=0.05, fitted_model=None, residuals=None, fitted_values=None)\nTest for homoscedasticity (constant variance) in linear regression residuals.\nHomoscedasticity is the assumption that residuals have constant variance across all levels of the independent variables. Violation of this assumption (heteroscedasticity) leads to inefficient coefficient estimates and incorrect standard errors in ordinary least squares (OLS) regression.\nThis function implements multiple statistical tests to detect heteroscedasticity:\n\nBreusch-Pagan test: Tests whether residual variance depends linearly on predictors. Null hypothesis: homoscedasticity (constant variance).\nWhite test: More general test that allows for non-linear relationships between variance and predictors. Includes squared terms and interactions. Null hypothesis: homoscedasticity.\nGoldfeld-Quandt test: Splits data by a predictor and compares variance in two subsets. Useful for detecting variance that increases/decreases with a specific predictor.\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nX\npd.DataFrame\nDataFrame of predictors (features). Each column is a predictor variable. Must contain only numeric columns.\nrequired\n\n\ny\npd.Series\nTarget variable (response). Must have the same length as X.\nrequired\n\n\nmethod\nTestMethod\nStatistical test(s) to perform: - “breusch_pagan”: Breusch-Pagan Lagrange multiplier test - “white”: White’s general heteroscedasticity test - “goldfeld_quandt”: Goldfeld-Quandt test (splits on first predictor by default) - “all”: Run all available tests\n\"breusch_pagan\"\n\n\nalpha\nfloat\nSignificance level for hypothesis tests. Common values: 0.01, 0.05, 0.10. Must be between 0 and 1 (exclusive).\n0.05\n\n\nfitted_model\noptional\nPre-fitted regression model object with predict() method. If None, an OLS model will be fitted internally using X and y. Useful for avoiding refitting when model already exists.\nNone\n\n\nresiduals\nnp.ndarray\nPre-computed residuals (y - y_pred). Must have same length as y. If None, residuals will be computed from fitted_model or internal fit. Cannot be specified without fitted_values.\nNone\n\n\nfitted_values\nnp.ndarray\nPre-computed fitted values (y_pred). Must have same length as y. If None, fitted values will be computed from fitted_model or internal fit. Cannot be specified without residuals.\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npd.DataFrame\nOne row per test performed, with columns: - “test” (str): Name of the test performed - “statistic” (float): Test statistic value, rounded to 3 decimals - “p_value” (float): P-value for the test, rounded to 4 decimals - “conclusion” (str): One of {“homoscedastic”, “heteroscedastic”} - “significant” (bool): True if p_value &lt; alpha (reject null hypothesis) Rows are sorted by test name alphabetically.\n\n\ndict\nOverall diagnostics containing: - “overall_conclusion” (str): “homoscedastic” if all tests pass, otherwise “heteroscedastic” - “n_tests_performed” (int): Number of tests conducted - “n_tests_significant” (int): Number of tests rejecting homoscedasticity - “alpha” (float): Echo of significance level used - “n_observations” (int): Sample size - “n_predictors” (int): Number of predictor variables - “recommendation” (str): Suggested action if heteroscedasticity detected\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nValueError\n- If X contains non-numeric columns - If X and y have different lengths - If alpha is not between 0 and 1 - If residuals is provided without fitted_values or vice versa - If residuals/fitted_values length doesn’t match y - If fewer than 10 observations are available (insufficient for testing)\n\n\nTypeError\n- If fitted_model is provided but lacks predict() method - If X is not a pandas DataFrame - If y is not a pandas Series\n\n\n\n\n\n\n\nAll tests assume residuals from a linear regression model.\nTests use chi-square or F-distributions depending on the method.\nThe Breusch-Pagan test is most powerful against linear heteroscedasticity.\nThe White test is more general but may have lower power with small samples.\nGoldfeld-Quandt test requires ordering data, which may be arbitrary for multivariate predictors.\nIf heteroscedasticity is detected, consider using robust standard errors (e.g., HC3, HC4) or weighted least squares (WLS) regression.\nMissing values in X or y will raise an error; clean data beforehand.\n\n\n\n\nBasic usage with internal model fitting:\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; np.random.seed(42)\n&gt;&gt;&gt; X = pd.DataFrame({\n...     'x1': np.linspace(1, 100, 100),\n...     'x2': np.random.randn(100)\n... })\n&gt;&gt;&gt; y = pd.Series(2 * X['x1'] + 3 * X['x2'] + np.random.randn(100))\n&gt;&gt;&gt; test_results, summary = check_homoscedasticity(X, y)\n&gt;&gt;&gt; print(summary[\"overall_conclusion\"])\n'homoscedastic'\nUsing a pre-fitted model:\n&gt;&gt;&gt; from sklearn.linear_model import LinearRegression\n&gt;&gt;&gt; model = LinearRegression().fit(X, y)\n&gt;&gt;&gt; test_results, summary = check_homoscedasticity(\n...     X, y, fitted_model=model\n... )\n&gt;&gt;&gt; print(test_results)\n          test  statistic   p_value      conclusion  significant\n0  breusch_pagan      2.345      0.309  homoscedastic        False\nRunning all tests:\n&gt;&gt;&gt; test_results, summary = check_homoscedasticity(\n...     X, y, method=\"all\", alpha=0.01\n... )\n&gt;&gt;&gt; print(summary[\"n_tests_performed\"])\n3\n&gt;&gt;&gt; print(summary[\"n_tests_significant\"])\n0\nDetecting heteroscedasticity (variance increases with x):\n&gt;&gt;&gt; X_hetero = pd.DataFrame({\n...     'x1': np.linspace(1, 100, 100)\n... })\n&gt;&gt;&gt; errors = np.random.randn(100) * X_hetero['x1']  # variance increases\n&gt;&gt;&gt; y_hetero = pd.Series(2 * X_hetero['x1'] + errors)\n&gt;&gt;&gt; test_results, summary = check_homoscedasticity(X_hetero, y_hetero)\n&gt;&gt;&gt; print(summary[\"overall_conclusion\"])\n'heteroscedastic'\n&gt;&gt;&gt; print(summary[\"recommendation\"])\n'Consider using robust standard errors (HC3/HC4) or weighted least squares.'\nUsing pre-computed residuals and fitted values:\n&gt;&gt;&gt; model = LinearRegression().fit(X, y)\n&gt;&gt;&gt; y_pred = model.predict(X)\n&gt;&gt;&gt; resid = y - y_pred\n&gt;&gt;&gt; test_results, summary = check_homoscedasticity(\n...     X, y,\n...     residuals=resid,\n...     fitted_values=y_pred\n... )\n&gt;&gt;&gt; print(test_results)\n          test  statistic   p_value      conclusion  significant\n0  breusch_pagan      2.345      0.309  homoscedastic        False\n\n\n\n.. [1] Breusch, T. S., & Pagan, A. R. (1979). A simple test for heteroscedasticity and random coefficient variation. Econometrica, 47(5), 1287-1294.\n.. [2] White, H. (1980). A heteroskedasticity-consistent covariance matrix estimator and a direct test for heteroskedasticity. Econometrica, 48(4), 817-838.\n.. [3] Goldfeld, S. M., & Quandt, R. E. (1965). Some tests for homoscedasticity. Journal of the American Statistical Association, 60(310), 539-547."
  },
  {
    "objectID": "tutorials/getting-started.html",
    "href": "tutorials/getting-started.html",
    "title": "Getting Started with lrassume",
    "section": "",
    "text": "Install from TestPyPI:\npip install -i https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple/ lrassume",
    "crumbs": [
      "Tutorials",
      "Getting Started with lrassume"
    ]
  },
  {
    "objectID": "tutorials/getting-started.html#installation",
    "href": "tutorials/getting-started.html#installation",
    "title": "Getting Started with lrassume",
    "section": "",
    "text": "Install from TestPyPI:\npip install -i https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple/ lrassume",
    "crumbs": [
      "Tutorials",
      "Getting Started with lrassume"
    ]
  },
  {
    "objectID": "tutorials/getting-started.html#what-is-lrassume",
    "href": "tutorials/getting-started.html#what-is-lrassume",
    "title": "Getting Started with lrassume",
    "section": "What is lrassume?",
    "text": "What is lrassume?\nlrassume (Linear Regression Assumption Validator) helps you validate the four core assumptions of linear regression:\n\nIndependence: Residuals are independent (no autocorrelation)\nLinearity: Linear relationship between predictors and target\nMulticollinearity: Predictors are not highly correlated\nHomoscedasticity: Constant variance in residuals",
    "crumbs": [
      "Tutorials",
      "Getting Started with lrassume"
    ]
  },
  {
    "objectID": "tutorials/getting-started.html#basic-workflow",
    "href": "tutorials/getting-started.html#basic-workflow",
    "title": "Getting Started with lrassume",
    "section": "Basic Workflow",
    "text": "Basic Workflow\nHere’s a typical workflow for validating a regression model:\n\nimport pandas as pd\nfrom lrassume import (\n    check_independence,\n    check_linearity,\n    check_multicollinearity_vif,\n    check_homoscedasticity\n)\n\n# Load your data\ndf = pd.read_csv(\"your_data.csv\")\n\n# 1. Check for linear relationships\nlinear_features = check_linearity(df, target=\"price\", threshold=0.7)\nprint(linear_features)\n\n# 2. Check for multicollinearity\nX = df.drop(columns=[\"price\"])\nvif_table, vif_summary = check_multicollinearity_vif(X)\nprint(vif_summary['overall_status'])\n\n# 3. Check independence of residuals\nindependence_result = check_independence(df, target=\"price\")\nprint(independence_result['is_independent'])\n\n# 4. Check homoscedasticity\ny = df[\"price\"]\ntest_results, summary = check_homoscedasticity(X, y, method=\"all\")\nprint(summary['overall_conclusion'])",
    "crumbs": [
      "Tutorials",
      "Getting Started with lrassume"
    ]
  },
  {
    "objectID": "tutorials/getting-started.html#next-steps",
    "href": "tutorials/getting-started.html#next-steps",
    "title": "Getting Started with lrassume",
    "section": "Next Steps",
    "text": "Next Steps\n\nIndependence Testing\nLinearity Assessment\nMulticollinearity Detection\nHomoscedasticity Testing",
    "crumbs": [
      "Tutorials",
      "Getting Started with lrassume"
    ]
  },
  {
    "objectID": "tutorials/homoscedasticity.html",
    "href": "tutorials/homoscedasticity.html",
    "title": "Homoscedasticity Testing",
    "section": "",
    "text": "Homoscedasticity means residuals have constant variance across all predictor values.\n\n\n\nBiased standard errors: Confidence intervals and p-values are incorrect\nInefficient estimates: Coefficients are unbiased but not optimal\nHypothesis testing issues: T-tests and F-tests may be invalid",
    "crumbs": [
      "Tutorials",
      "Homoscedasticity Testing"
    ]
  },
  {
    "objectID": "tutorials/homoscedasticity.html#understanding-homoscedasticity",
    "href": "tutorials/homoscedasticity.html#understanding-homoscedasticity",
    "title": "Homoscedasticity Testing",
    "section": "",
    "text": "Homoscedasticity means residuals have constant variance across all predictor values.\n\n\n\nBiased standard errors: Confidence intervals and p-values are incorrect\nInefficient estimates: Coefficients are unbiased but not optimal\nHypothesis testing issues: T-tests and F-tests may be invalid",
    "crumbs": [
      "Tutorials",
      "Homoscedasticity Testing"
    ]
  },
  {
    "objectID": "tutorials/homoscedasticity.html#available-tests",
    "href": "tutorials/homoscedasticity.html#available-tests",
    "title": "Homoscedasticity Testing",
    "section": "Available Tests",
    "text": "Available Tests\n\n\n\n\n\n\n\nTest\nBest For\n\n\n\n\nBreusch-Pagan\nGeneral heteroscedasticity detection\n\n\nWhite\nDetects complex forms of heteroscedasticity\n\n\nGoldfeld-Quandt\nHeteroscedasticity that increases/decreases monotonically",
    "crumbs": [
      "Tutorials",
      "Homoscedasticity Testing"
    ]
  },
  {
    "objectID": "tutorials/homoscedasticity.html#example-single-test",
    "href": "tutorials/homoscedasticity.html#example-single-test",
    "title": "Homoscedasticity Testing",
    "section": "Example: Single Test",
    "text": "Example: Single Test\n\nimport pandas as pd\nimport numpy as np\nfrom lrassume import check_homoscedasticity\n\nnp.random.seed(42)\nX = pd.DataFrame({\n    'x1': np.linspace(1, 100, 100),\n    'x2': np.random.randn(100)\n})\ny = pd.Series(2 * X['x1'] + 3 * X['x2'] + np.random.randn(100))\n\n# Run Breusch-Pagan test\ntest_results, summary = check_homoscedasticity(\n    X, y,\n    method=\"breusch_pagan\",\n    alpha=0.05\n)\n\nprint(f\"Conclusion: {summary['overall_conclusion']}\")\nprint(\"\\nTest Results:\")\nprint(test_results)",
    "crumbs": [
      "Tutorials",
      "Homoscedasticity Testing"
    ]
  },
  {
    "objectID": "tutorials/homoscedasticity.html#example-all-tests",
    "href": "tutorials/homoscedasticity.html#example-all-tests",
    "title": "Homoscedasticity Testing",
    "section": "Example: All Tests",
    "text": "Example: All Tests\n\n# Run all three tests\ntest_results, summary = check_homoscedasticity(X, y, method=\"all\")\n\nprint(f\"Overall: {summary['overall_conclusion']}\")\nprint(f\"Tests agreeing: {summary['tests_in_agreement']}\")\nprint(\"\\nDetailed Results:\")\nprint(test_results)\n\nExpected Output:\nOverall: homoscedastic\nTests agreeing: 3\n\nDetailed Results:\n            test  statistic  p_value     conclusion  significant\n0  breusch_pagan      1.234   0.5391  homoscedastic        False\n1          white      2.156   0.3407  homoscedastic        False\n2  goldfeld_quandt 0.987   0.4123  homoscedastic        False",
    "crumbs": [
      "Tutorials",
      "Homoscedasticity Testing"
    ]
  },
  {
    "objectID": "tutorials/homoscedasticity.html#using-pre-fitted-models",
    "href": "tutorials/homoscedasticity.html#using-pre-fitted-models",
    "title": "Homoscedasticity Testing",
    "section": "Using Pre-fitted Models",
    "text": "Using Pre-fitted Models\n\nfrom sklearn.linear_model import LinearRegression\n\n# Fit your model\nmodel = LinearRegression().fit(X, y)\n\n# Test with fitted model\ntest_results, summary = check_homoscedasticity(\n    X, y,\n    fitted_model=model,\n    method=\"breusch_pagan\"\n)",
    "crumbs": [
      "Tutorials",
      "Homoscedasticity Testing"
    ]
  },
  {
    "objectID": "tutorials/homoscedasticity.html#custom-significance-level",
    "href": "tutorials/homoscedasticity.html#custom-significance-level",
    "title": "Homoscedasticity Testing",
    "section": "Custom Significance Level",
    "text": "Custom Significance Level\n\n# 99% confidence (stricter)\ntest_results, summary = check_homoscedasticity(\n    X, y,\n    alpha=0.01\n)\n\n# 90% confidence (more lenient)\ntest_results, summary = check_homoscedasticity(\n    X, y,\n    alpha=0.10\n)",
    "crumbs": [
      "Tutorials",
      "Homoscedasticity Testing"
    ]
  },
  {
    "objectID": "tutorials/homoscedasticity.html#solutions-for-heteroscedasticity",
    "href": "tutorials/homoscedasticity.html#solutions-for-heteroscedasticity",
    "title": "Homoscedasticity Testing",
    "section": "Solutions for Heteroscedasticity",
    "text": "Solutions for Heteroscedasticity\n\nTransform the target variable\n\n   # Log transformation\n   y_log = np.log(y + 1)\n   \n   # Square root transformation\n   y_sqrt = np.sqrt(y)\n\nWeighted Least Squares (WLS)\n\n   from statsmodels.regression.linear_model import WLS\n   \n   # Weight by inverse variance\n   weights = 1 / residuals**2\n   model_wls = WLS(y, X, weights=weights).fit()\n\nRobust Standard Errors\n\n   import statsmodels.api as sm\n   \n   model = sm.OLS(y, X).fit()\n   robust_results = model.get_robustcov_results(cov_type='HC3')\n\nUse a different model\n\nGeneralized Linear Models (GLM)\nQuantile regression\nTree-based models",
    "crumbs": [
      "Tutorials",
      "Homoscedasticity Testing"
    ]
  },
  {
    "objectID": "tutorials/homoscedasticity.html#visualizing-heteroscedasticity",
    "href": "tutorials/homoscedasticity.html#visualizing-heteroscedasticity",
    "title": "Homoscedasticity Testing",
    "section": "Visualizing Heteroscedasticity",
    "text": "Visualizing Heteroscedasticity\n\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\nmodel = LinearRegression().fit(X, y)\nresiduals = y - model.predict(X)\nfitted = model.predict(X)\n\nplt.scatter(fitted, residuals)\nplt.axhline(y=0, color='r', linestyle='--')\nplt.xlabel('Fitted Values')\nplt.ylabel('Residuals')\nplt.title('Residual Plot')\nplt.show()\n\nGood pattern: Random scatter around zero\nBad pattern: Funnel shape (variance increases/decreases)",
    "crumbs": [
      "Tutorials",
      "Homoscedasticity Testing"
    ]
  },
  {
    "objectID": "tutorials/multicollinearity.html",
    "href": "tutorials/multicollinearity.html",
    "title": "Multicollinearity Detection",
    "section": "",
    "text": "Multicollinearity occurs when predictor variables are highly correlated with each other.\n\n\n\nInflated standard errors: Less precise coefficient estimates\nUnstable coefficients: Small data changes cause large coefficient changes\nDifficult interpretation: Hard to isolate individual predictor effects",
    "crumbs": [
      "Tutorials",
      "Multicollinearity Detection"
    ]
  },
  {
    "objectID": "tutorials/multicollinearity.html#understanding-multicollinearity",
    "href": "tutorials/multicollinearity.html#understanding-multicollinearity",
    "title": "Multicollinearity Detection",
    "section": "",
    "text": "Multicollinearity occurs when predictor variables are highly correlated with each other.\n\n\n\nInflated standard errors: Less precise coefficient estimates\nUnstable coefficients: Small data changes cause large coefficient changes\nDifficult interpretation: Hard to isolate individual predictor effects",
    "crumbs": [
      "Tutorials",
      "Multicollinearity Detection"
    ]
  },
  {
    "objectID": "tutorials/multicollinearity.html#using-vif-variance-inflation-factor",
    "href": "tutorials/multicollinearity.html#using-vif-variance-inflation-factor",
    "title": "Multicollinearity Detection",
    "section": "Using VIF (Variance Inflation Factor)",
    "text": "Using VIF (Variance Inflation Factor)\nThe check_multicollinearity_vif() function calculates VIF for each predictor.\n\nVIF Interpretation\n\n\n\nVIF Range\nSeverity\nAction\n\n\n\n\n&lt; 5\nNone\n✓ No concern\n\n\n5-10\nModerate\n⚠️ Monitor\n\n\n≥ 10\nSevere\n🚨 Address issue",
    "crumbs": [
      "Tutorials",
      "Multicollinearity Detection"
    ]
  },
  {
    "objectID": "tutorials/multicollinearity.html#example",
    "href": "tutorials/multicollinearity.html#example",
    "title": "Multicollinearity Detection",
    "section": "Example",
    "text": "Example\n\nimport pandas as pd\nfrom lrassume import check_multicollinearity_vif\n\n# Housing data with correlated features\nX = pd.DataFrame({\n    \"sqft\": [800, 900, 1000, 1100, 1200, 1300, 1400, 1500],\n    \"bedrooms\": [1, 2, 1, 3, 2, 4, 3, 5],\n    \"bathrooms\": [1, 2, 1, 3, 2, 4, 3, 5],  # Highly correlated with bedrooms!\n    \"age\": [30, 5, 40, 10, 25, 15, 35, 20]\n})\n\nvif_table, summary = check_multicollinearity_vif(X, warn_threshold=5.0)\n\nprint(f\"Overall Status: {summary['overall_status']}\")\nprint(\"\\nVIF Table:\")\nprint(vif_table)\n\nPossible Output:\nOverall Status: severe\n\nVIF Table:\n     feature        vif   level\n0  bedrooms  15.200000  severe\n1  bathrooms 15.100000  severe\n2      sqft   3.450000      ok\n3       age   2.100000      ok",
    "crumbs": [
      "Tutorials",
      "Multicollinearity Detection"
    ]
  },
  {
    "objectID": "tutorials/multicollinearity.html#custom-thresholds",
    "href": "tutorials/multicollinearity.html#custom-thresholds",
    "title": "Multicollinearity Detection",
    "section": "Custom Thresholds",
    "text": "Custom Thresholds\n\n# Stricter detection\nvif_table, summary = check_multicollinearity_vif(\n    X,\n    warn_threshold=3.0,\n    severe_threshold=5.0\n)",
    "crumbs": [
      "Tutorials",
      "Multicollinearity Detection"
    ]
  },
  {
    "objectID": "tutorials/multicollinearity.html#solutions-for-high-multicollinearity",
    "href": "tutorials/multicollinearity.html#solutions-for-high-multicollinearity",
    "title": "Multicollinearity Detection",
    "section": "Solutions for High Multicollinearity",
    "text": "Solutions for High Multicollinearity\n\nRemove one correlated predictor\n\n   # Remove bathrooms (highly correlated with bedrooms)\n   X_cleaned = X.drop(columns=['bathrooms'])\n\nCombine correlated features\n\n   # Create total_rooms = bedrooms + bathrooms\n   X['total_rooms'] = X['bedrooms'] + X['bathrooms']\n   X = X.drop(columns=['bedrooms', 'bathrooms'])\n\nPrincipal Component Analysis (PCA)\n\n   from sklearn.decomposition import PCA\n   pca = PCA(n_components=3)\n   X_pca = pca.fit_transform(X)\n\nRegularization (Ridge/Lasso regression)\n\n   from sklearn.linear_model import Ridge\n   model = Ridge(alpha=1.0)",
    "crumbs": [
      "Tutorials",
      "Multicollinearity Detection"
    ]
  },
  {
    "objectID": "tutorials/multicollinearity.html#handling-categorical-variables",
    "href": "tutorials/multicollinearity.html#handling-categorical-variables",
    "title": "Multicollinearity Detection",
    "section": "Handling Categorical Variables",
    "text": "Handling Categorical Variables\n\n# Automatically drop non-numeric columns\nvif_table, summary = check_multicollinearity_vif(\n    df,\n    target_column='price',\n    categorical='drop'\n)\n\n# Check which columns were dropped\nprint(summary['dropped_non_numeric'])",
    "crumbs": [
      "Tutorials",
      "Multicollinearity Detection"
    ]
  },
  {
    "objectID": "index.html#running-the-test-suite-locally-developers",
    "href": "index.html#running-the-test-suite-locally-developers",
    "title": "Welcome to lrassume",
    "section": "",
    "text": "The test suite is executed using pytest. In CI this is managed via Hatch, but tests can also be run locally using pytest.\n\n\n\nconda install pytest\n# or\npip install pytest\n\n\n\n\npytest",
    "crumbs": [
      "Welcome to lrassume"
    ]
  },
  {
    "objectID": "index.html#continuous-integration-automated-testing",
    "href": "index.html#continuous-integration-automated-testing",
    "title": "Welcome to lrassume",
    "section": "",
    "text": "This project uses GitHub Actions to automatically run the test suite.\nThe tests are executed automatically on: - Pull requests - Pushes to the main branch - A scheduled weekly run\nThe test suite is executed using Hatch, which runs the project’s configured pytest test environment across multiple operating systems and Python versions.\nNo manual action is required to trigger these tests.\nThe GitHub Actions workflow responsible for running the test suite is located at:\n.github/workflows/test.yml",
    "crumbs": [
      "Welcome to lrassume"
    ]
  },
  {
    "objectID": "index.html#documentation",
    "href": "index.html#documentation",
    "title": "Welcome to lrassume",
    "section": "",
    "text": "The full package documentation is built with Quartodoc and deployed automatically to GitHub Pages.\nLive documentation: https://ubc-mds.github.io/lrassume/\n\n\nTo preview documentation changes before pushing:\n\nEnsure you are in the development environment:\n\n   conda activate lrassume\n\nInstall documentation dependencies:\n\n   pip install -e \".[docs]\"\n\nBuild the documentation:\n\n   quartodoc build\n\nPreview the documentation locally:\n\n   quarto preview\nThis will open the documentation site in your browser.\n\n\n\nTo update documentation:\n\nEdit docstrings in Python source files (lrassume/*.py)\nRebuild locally using the steps above to verify changes\nCommit and push to your branch\n\nNote: The documentation is automatically generated from your Python docstrings.\n\n\n\nDocumentation deployment is fully automated using GitHub Actions.\nOn every push to the main branch:\n\nGitHub Actions builds the documentation using Quarto and Quartodoc\nThe rendered site is deployed to GitHub Pages\n\nNo manual deployment steps are required.\nThe workflow file can be found at:\n.github/workflows/docs-publish.yml",
    "crumbs": [
      "Welcome to lrassume"
    ]
  },
  {
    "objectID": "tutorials/independence.html",
    "href": "tutorials/independence.html",
    "title": "Independence Testing",
    "section": "",
    "text": "Residuals should be independent of each other. Violations occur when:\n\nWorking with time-series data\nSpatially correlated observations\nClustered data (e.g., students within schools)",
    "crumbs": [
      "Tutorials",
      "Independence Testing"
    ]
  },
  {
    "objectID": "tutorials/independence.html#understanding-independence",
    "href": "tutorials/independence.html#understanding-independence",
    "title": "Independence Testing",
    "section": "",
    "text": "Residuals should be independent of each other. Violations occur when:\n\nWorking with time-series data\nSpatially correlated observations\nClustered data (e.g., students within schools)",
    "crumbs": [
      "Tutorials",
      "Independence Testing"
    ]
  },
  {
    "objectID": "tutorials/independence.html#the-durbin-watson-test",
    "href": "tutorials/independence.html#the-durbin-watson-test",
    "title": "Independence Testing",
    "section": "The Durbin-Watson Test",
    "text": "The Durbin-Watson Test\nThe check_independence() function uses the Durbin-Watson test to detect autocorrelation.\n\nInterpreting the Statistic\n\n1.5 to 2.5: No significant autocorrelation ✓\n&lt; 1.5: Positive autocorrelation (successive residuals are similar)\n&gt; 2.5: Negative autocorrelation (successive residuals alternate)",
    "crumbs": [
      "Tutorials",
      "Independence Testing"
    ]
  },
  {
    "objectID": "tutorials/independence.html#example-time-series-data",
    "href": "tutorials/independence.html#example-time-series-data",
    "title": "Independence Testing",
    "section": "Example: Time Series Data",
    "text": "Example: Time Series Data\n\nimport pandas as pd\nfrom lrassume import check_independence\n\n# Monthly sales data\ndf = pd.DataFrame({\n    \"advertising\": [10, 15, 12, 18, 20, 25, 22, 28, 30, 35],\n    \"month\": range(1, 11),\n    \"sales\": [100, 150, 120, 180, 200, 250, 220, 280, 300, 350]\n})\n\nresult = check_independence(df, target=\"sales\")\n\nprint(f\"DW Statistic: {result['dw_statistic']:.3f}\")\nprint(f\"Independent: {result['is_independent']}\")\nprint(result['message'])",
    "crumbs": [
      "Tutorials",
      "Independence Testing"
    ]
  },
  {
    "objectID": "tutorials/independence.html#what-to-do-if-independence-fails",
    "href": "tutorials/independence.html#what-to-do-if-independence-fails",
    "title": "Independence Testing",
    "section": "What to Do if Independence Fails",
    "text": "What to Do if Independence Fails\nIf the test detects autocorrelation:\n\nTime series models: Consider ARIMA, VAR, or other time-series methods\nAdd lagged variables: Include previous values as predictors\nCluster-robust standard errors: Adjust standard errors for clustering\nMixed-effects models: Account for hierarchical structure",
    "crumbs": [
      "Tutorials",
      "Independence Testing"
    ]
  },
  {
    "objectID": "tutorials/independence.html#key-points",
    "href": "tutorials/independence.html#key-points",
    "title": "Independence Testing",
    "section": "Key Points",
    "text": "Key Points\n\nThe function automatically fits a linear model using all numeric features\nIt handles the intercept term internally\nOnly the target column needs to be specified",
    "crumbs": [
      "Tutorials",
      "Independence Testing"
    ]
  },
  {
    "objectID": "tutorials/linearity.html",
    "href": "tutorials/linearity.html",
    "title": "Linearity Assessment",
    "section": "",
    "text": "Linear regression assumes a linear relationship between each predictor and the target variable.",
    "crumbs": [
      "Tutorials",
      "Linearity Assessment"
    ]
  },
  {
    "objectID": "tutorials/linearity.html#understanding-linearity",
    "href": "tutorials/linearity.html#understanding-linearity",
    "title": "Linearity Assessment",
    "section": "",
    "text": "Linear regression assumes a linear relationship between each predictor and the target variable.",
    "crumbs": [
      "Tutorials",
      "Linearity Assessment"
    ]
  },
  {
    "objectID": "tutorials/linearity.html#using-check_linearity",
    "href": "tutorials/linearity.html#using-check_linearity",
    "title": "Linearity Assessment",
    "section": "Using check_linearity()",
    "text": "Using check_linearity()\nThe function computes Pearson correlation coefficients to identify features with strong linear relationships.\n\nExample: Housing Prices\n\nimport pandas as pd\nfrom lrassume import check_linearity\n\ndf = pd.DataFrame({\n    \"sqft\": [500, 700, 900, 1100, 1300, 1500],\n    \"num_rooms\": [1, 2, 1, 3, 2, 4],\n    \"age\": [40, 25, 20, 5, 15, 10],\n    \"distance_to_center\": [15, 12, 8, 5, 10, 6],\n    \"price\": [150, 210, 260, 320, 280, 350]\n})\n\n# Find features with |correlation| &gt;= 0.7\nlinear_features = check_linearity(df, target=\"price\", threshold=0.7)\nprint(linear_features)\n\nExpected Output:\n  feature  correlation\n0    sqft        0.985\n1     age       -0.920",
    "crumbs": [
      "Tutorials",
      "Linearity Assessment"
    ]
  },
  {
    "objectID": "tutorials/linearity.html#interpreting-results",
    "href": "tutorials/linearity.html#interpreting-results",
    "title": "Linearity Assessment",
    "section": "Interpreting Results",
    "text": "Interpreting Results\n\nHigh positive correlation (close to +1): Feature increases with target\nHigh negative correlation (close to -1): Feature decreases with target\nLow correlation (close to 0): Weak linear relationship",
    "crumbs": [
      "Tutorials",
      "Linearity Assessment"
    ]
  },
  {
    "objectID": "tutorials/linearity.html#custom-thresholds",
    "href": "tutorials/linearity.html#custom-thresholds",
    "title": "Linearity Assessment",
    "section": "Custom Thresholds",
    "text": "Custom Thresholds\n\n# More strict: only very strong relationships\nstrict_features = check_linearity(df, target=\"price\", threshold=0.9)\n\n# More lenient: moderate relationships\nlenient_features = check_linearity(df, target=\"price\", threshold=0.5)",
    "crumbs": [
      "Tutorials",
      "Linearity Assessment"
    ]
  },
  {
    "objectID": "tutorials/linearity.html#what-to-do-if-linearity-fails",
    "href": "tutorials/linearity.html#what-to-do-if-linearity-fails",
    "title": "Linearity Assessment",
    "section": "What to Do if Linearity Fails",
    "text": "What to Do if Linearity Fails\nIf features show weak linear relationships:\n\nTransform variables: Try log, sqrt, or polynomial transformations\nAdd polynomial terms: Include x², x³ terms\nBinning: Convert continuous variables to categories\nNon-linear models: Consider tree-based models, GAMs, or neural networks",
    "crumbs": [
      "Tutorials",
      "Linearity Assessment"
    ]
  },
  {
    "objectID": "tutorials/linearity.html#visualizing-relationships",
    "href": "tutorials/linearity.html#visualizing-relationships",
    "title": "Linearity Assessment",
    "section": "Visualizing Relationships",
    "text": "Visualizing Relationships\n\nimport matplotlib.pyplot as plt\n\n# Scatter plot to visually check linearity\nplt.scatter(df['sqft'], df['price'])\nplt.xlabel('Square Feet')\nplt.ylabel('Price')\nplt.title('Relationship between sqft and price')\nplt.show()",
    "crumbs": [
      "Tutorials",
      "Linearity Assessment"
    ]
  }
]